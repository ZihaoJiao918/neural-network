{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "a3_part1_B.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZW2Zw4b7kpz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.special import expit as sigmoid\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHFI2BfjG0FP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_data(number_of_sample_entries):\n",
        "\n",
        " #initialize size\n",
        "  data = np.ndarray((number_of_sample_entries,3))\n",
        "  label = np.zeros((number_of_sample_entries,3))\n",
        "  \n",
        "  #class 1\n",
        "  class_1 = number_of_sample_entries//3\n",
        "  data[0:class_1, :] = np.random.uniform(low=1, high=5,size=(class_1,3))\n",
        "  label[0:class_1, :] = np.array([1,0,0])\n",
        "  #class 2\n",
        "  class_2 = class_1 + number_of_sample_entries//3\n",
        "  data[class_1:class_2, :] = np.random.uniform(low=10, high=15,size=(class_1,3))\n",
        "  label[class_1:class_2, :] = np.array([0,1,0])\n",
        "  #class 3\n",
        "  class_3 = class_2 + number_of_sample_entries//3\n",
        "  data[class_2:class_3, :] = np.random.uniform(low=20, high=25,size=(class_1,3))\n",
        "  label[class_2:class_3, :] = np.array([0,0,1])\n",
        "\n",
        "  #build it into datafram\n",
        "  x = pd.DataFrame(data)\n",
        "  labels = pd.DataFrame(label)\n",
        "  #split data and shuffle data\n",
        "  X_train, X_test, y_train, y_test = train_test_split(x, labels, test_size = 0.3, shuffle=True)\n",
        "\n",
        "  #return it to array\n",
        "  label_train = y_train.to_numpy()\n",
        "  data_train = X_train.to_numpy()\n",
        "  label_test = y_test.to_numpy()\n",
        "  data_test = X_test.to_numpy()\n",
        "\n",
        "\n",
        "  return label_train,data_train,label_test,data_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SodCFsFTG4VR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label_train,data_train,label_test,data_test = generate_data(6000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6V_PR5rks_PF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def relu(X):\n",
        "   return np.maximum(X,0)\n",
        "\n",
        "\n",
        "\n",
        "def relu_derivative(x):\n",
        "  return np.where(x>0, 1, 0)\n",
        "\n",
        "\n",
        "\n",
        "def softmax(x):\n",
        "  list_res=[]\n",
        "  for i in range(len(x)):\n",
        "    res = np.exp(x[i])/np.sum(np.exp(x[i]))\n",
        "    list_res.append(res)\n",
        "  return np.array(list_res)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K590eYDKMQ5k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Initialize our neural network parameters.\n",
        "params = {}\n",
        "params['w_1'] = np.random.randn(3, 3)\n",
        "params['b_1'] = np.zeros(3)\n",
        "\n",
        "params['w_2'] = np.random.randn(3, 3)\n",
        "params['b_2'] = np.zeros(3)\n",
        "\n",
        "params['w_3'] = np.random.randn(3, 3)\n",
        "params['b_3'] = np.zeros(3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WUTvaxoUTGOl",
        "colab_type": "code",
        "outputId": "7418dff2-119e-412a-c0da-936028f160ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "params"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'b_1': array([0., 0., 0.]),\n",
              " 'b_2': array([0., 0., 0.]),\n",
              " 'b_3': array([0., 0., 0.]),\n",
              " 'w_1': array([[ 0.13095318,  0.08409127,  0.08453143],\n",
              "        [-0.54589556,  0.16214619,  1.19208146],\n",
              "        [-0.99722143, -0.20116152, -0.27684717]]),\n",
              " 'w_2': array([[-0.26664542,  0.03836868, -1.66634156],\n",
              "        [-0.31305133,  1.07765227,  1.14124247],\n",
              "        [-1.14159903,  0.10028088,  1.69827081]]),\n",
              " 'w_3': array([[ 0.20220617,  1.63474355, -1.73137934],\n",
              "        [ 0.81286237, -0.64662802,  0.66244508],\n",
              "        [ 0.00350068,  1.37333547, -0.75474401]])}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jgbAPB6q8Y7i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def backprop(I, t, params):\n",
        "    N = I.shape[0]\n",
        "    \n",
        "    # Perform forwards computation.\n",
        "    J_in = np.dot(I, params['w_1'].T)  + params['b_1']\n",
        "    J_out = relu(J_in)\n",
        "    K_in = np.dot(J_out,params['w_2'].T) + params['b_2']\n",
        "    K_out = sigmoid(K_in)\n",
        "    L_in = np.dot(K_out,params['w_3'])+params['b_3']\n",
        "    L_out = softmax(L_in)\n",
        "\n",
        "    loss = (1./N) * np.sum(-t * np.log(L_out) - (1 - t) * np.log(1 - L_out))\n",
        "    \n",
        "    # Perform backwards computation.\n",
        "    loss_bar = 1\n",
        "    L_out_bar = ((-t)/L_out) + ((1-t)/(1-L_out))\n",
        "    L_in_bar = L_out_bar * softmax(L_in) * (1-softmax(L_in))\n",
        "    w_3_bar = np.dot(K_out.T, L_in_bar)\n",
        "    b_3_bar = np.dot(L_in_bar.T,np.ones(N))\n",
        "    K_out_bar = np.dot(L_in_bar,params['w_3'].T)\n",
        "    K_in_bar = K_out_bar * sigmoid(K_in) * (1-sigmoid(K_in))\n",
        "    w_2_bar = np.dot(J_out.T , K_in_bar)\n",
        "    b_2_bar = np.dot(K_in_bar.T,np.ones(N))\n",
        "    J_out_bar = np.dot(K_in_bar , params['w_2'].T)\n",
        "    \n",
        "    J_in_bar = J_out_bar * relu_derivative(J_out)\n",
        "    w_1_bar = np.dot(J_in_bar.T,I)\n",
        "    b_1_bar = np.dot(J_in_bar.T,np.ones(N))\n",
        "\n",
        "\n",
        "\n",
        "    grads = {}\n",
        "    grads['w_3'] = w_3_bar \n",
        "    grads['b_3'] = b_3_bar\n",
        "    grads['w_2'] = w_2_bar\n",
        "    grads['b_2'] = b_2_bar\n",
        "    grads['w_1'] = w_2_bar\n",
        "    grads['b_1'] = b_2_bar\n",
        "\n",
        "\n",
        "    return grads,loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y5L8wNLDGXZ_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "6ca57aae-2a06-44ca-9011-7358fae2ec0d"
      },
      "source": [
        "\"\"\"\n",
        "alpha = 0.00002\n",
        "cost_list=[]\n",
        "iteration=0\n",
        "loss=1\n",
        "while loss>0.6:\n",
        "    iteration+=1        \n",
        "    grads, loss = backprop(data_train, label_train, params)\n",
        "    for k in params:\n",
        "        params[k] -= alpha * grads[k]\n",
        "    cost_list.append(loss)\n",
        "\"\"\""
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nalpha = 0.00002\\ncost_list=[]\\niteration=0\\nloss=1\\nwhile loss>0.6:\\n    iteration+=1        \\n    grads, loss = backprop(data_train, label_train, params)\\n    for k in params:\\n        params[k] -= alpha * grads[k]\\n    cost_list.append(loss)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19FSPkgwBcJU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "alpha = 0.00002\n",
        "cost_list=[]\n",
        "number_steps = 10000\n",
        "for step in range(number_steps):      \n",
        "    grads, loss = backprop(data_train, label_train, params)\n",
        "    for k in params:\n",
        "        params[k] -= alpha * grads[k]\n",
        "    cost_list.append(loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odnLGEFTagFh",
        "colab_type": "code",
        "outputId": "4ee7cfd2-4161-46fc-892a-273e82c854a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "plt.plot(cost_list)\n",
        "plt.show()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WqIaS1QmFpj7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "9e1cd673-3ab0-4dbb-dbb9-9982d1658174"
      },
      "source": [
        "params"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'b_1': array([11.94692475,  0.44241461,  0.35109688]),\n",
              " 'b_2': array([11.94692475,  0.44241461,  0.35109688]),\n",
              " 'b_3': array([-2.69551367,  0.97924416,  1.71626951]),\n",
              " 'w_1': array([[-0.15835763,  0.6173231 ,  0.48571954],\n",
              "        [-1.84938517, -1.90766899,  3.20121433],\n",
              "        [-0.99722143, -0.20116152, -0.27684717]]),\n",
              " 'w_2': array([[-0.55595624,  0.57160051, -1.26515345],\n",
              "        [-1.61654094, -0.9921629 ,  3.15037534],\n",
              "        [-1.14159903,  0.10028088,  1.69827081]]),\n",
              " 'w_3': array([[ 6.90761415,  0.49501025, -7.29705402],\n",
              "        [ 0.12152897,  0.07805653,  0.62909393],\n",
              "        [ 1.50893798,  0.29002243, -1.17686828]])}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fln_Gugl7kTY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def forward(I, params):\n",
        "    N = I.shape[0]\n",
        "    \n",
        "    # Perform forwards computation.\n",
        "    J_in = np.dot(I, params['w_1'].T)  + params['b_1']\n",
        "    J_out = relu(J_in)\n",
        "    K_in = np.dot(J_out,params['w_2'].T) + params['b_2']\n",
        "    K_out = sigmoid(K_in)\n",
        "    L_in = np.dot(K_out,params['w_3'])+params['b_3']\n",
        "    L_out = softmax(L_in)\n",
        "    return L_out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQ69Xt_49Uhm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "c47dc8a4-f62e-44b6-de8e-748511b61c57"
      },
      "source": [
        "prediction = forward(data_test,params)\n",
        "pred_df = pd.DataFrame(prediction,columns=['[d   a','   t   ','  a]'])\n",
        "label_df = pd.DataFrame(label_test,columns=['[L  a','b  e','l  s]'])\n",
        "result = pd.concat([pred_df,label_df],axis=1)\n",
        "result.head(10)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>[d   a</th>\n",
              "      <th>t</th>\n",
              "      <th>a]</th>\n",
              "      <th>[L  a</th>\n",
              "      <th>b  e</th>\n",
              "      <th>l  s]</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.289326</td>\n",
              "      <td>0.666513</td>\n",
              "      <td>0.044161</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.033265</td>\n",
              "      <td>0.556520</td>\n",
              "      <td>0.410214</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.008425</td>\n",
              "      <td>0.325983</td>\n",
              "      <td>0.665592</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.114386</td>\n",
              "      <td>0.722537</td>\n",
              "      <td>0.163077</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.008279</td>\n",
              "      <td>0.323463</td>\n",
              "      <td>0.668258</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.034964</td>\n",
              "      <td>0.565297</td>\n",
              "      <td>0.399739</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.932174</td>\n",
              "      <td>0.067759</td>\n",
              "      <td>0.000067</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.008214</td>\n",
              "      <td>0.322319</td>\n",
              "      <td>0.669467</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.931431</td>\n",
              "      <td>0.068499</td>\n",
              "      <td>0.000069</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.026399</td>\n",
              "      <td>0.515363</td>\n",
              "      <td>0.458238</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     [d   a      t           a]  [L  a  b  e  l  s]\n",
              "0  0.289326  0.666513  0.044161    0.0   1.0    0.0\n",
              "1  0.033265  0.556520  0.410214    0.0   1.0    0.0\n",
              "2  0.008425  0.325983  0.665592    0.0   0.0    1.0\n",
              "3  0.114386  0.722537  0.163077    0.0   1.0    0.0\n",
              "4  0.008279  0.323463  0.668258    0.0   0.0    1.0\n",
              "5  0.034964  0.565297  0.399739    0.0   1.0    0.0\n",
              "6  0.932174  0.067759  0.000067    1.0   0.0    0.0\n",
              "7  0.008214  0.322319  0.669467    0.0   0.0    1.0\n",
              "8  0.931431  0.068499  0.000069    1.0   0.0    0.0\n",
              "9  0.026399  0.515363  0.458238    0.0   1.0    0.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    }
  ]
}